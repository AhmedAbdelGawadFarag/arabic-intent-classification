{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openpyxl\n!pip install gdown\n!pip install farasapy","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T02:05:12.322463Z","iopub.execute_input":"2022-07-03T02:05:12.322992Z","iopub.status.idle":"2022-07-03T02:05:54.217049Z","shell.execute_reply.started":"2022-07-03T02:05:12.322899Z","shell.execute_reply":"2022-07-03T02:05:54.216228Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!gdown 1h620Wmx1yvkTKibH6N2wCNddOakBTUzg -O data.xlsx\n!git clone https://github.com/aub-mind/arabert","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:05:54.220675Z","iopub.execute_input":"2022-07-03T02:05:54.220894Z","iopub.status.idle":"2022-07-03T02:05:58.666947Z","shell.execute_reply.started":"2022-07-03T02:05:54.220869Z","shell.execute_reply":"2022-07-03T02:05:58.666087Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import TFBertModel, BertTokenizer, BertConfig\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\nfrom arabert.preprocess import ArabertPreprocessor\n\narabert_prep = ArabertPreprocessor(model_name='aubmindlab/bert-base-arabertv02-twitter')\nMAX_LENGHT = 32\nconfig = BertConfig.from_pretrained( 'aubmindlab/bert-base-arabertv02-twitter', output_hidden_states=False)    \npre = BertTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv02-twitter\")\nbert = TFBertModel.from_pretrained(\"aubmindlab/bert-base-arabertv02-twitter\", config=config, from_pt=True, trainable=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T02:05:58.668390Z","iopub.execute_input":"2022-07-03T02:05:58.668664Z","iopub.status.idle":"2022-07-03T02:06:44.165083Z","shell.execute_reply.started":"2022-07-03T02:05:58.668625Z","shell.execute_reply":"2022-07-03T02:06:44.164245Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_dict = pd.read_excel(\"data.xlsx\", sheet_name=None)\ndf = pd.concat(df_dict, axis=0, ignore_index=True)\nclasses = df.intent.unique().tolist()\nprint(classes)\n#df.groupby('intent').nunique()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:06:44.168243Z","iopub.execute_input":"2022-07-03T02:06:44.168460Z","iopub.status.idle":"2022-07-03T02:06:44.797842Z","shell.execute_reply.started":"2022-07-03T02:06:44.168431Z","shell.execute_reply":"2022-07-03T02:06:44.797087Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['text'].apply(lambda x: arabert_prep.preprocess(x))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:08:22.454803Z","iopub.execute_input":"2022-07-03T02:08:22.455382Z","iopub.status.idle":"2022-07-03T02:08:22.536149Z","shell.execute_reply.started":"2022-07-03T02:08:22.455343Z","shell.execute_reply":"2022-07-03T02:08:22.535448Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(df[\"text\"], df[\"intent\"],\n                                                    stratify=df[\"intent\"], \n                                                    test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:08:25.500971Z","iopub.execute_input":"2022-07-03T02:08:25.501715Z","iopub.status.idle":"2022-07-03T02:08:26.090705Z","shell.execute_reply.started":"2022-07-03T02:08:25.501676Z","shell.execute_reply":"2022-07-03T02:08:26.089937Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#X = X.apply(lambda x: pre(x, return_tensors=\"tf\"))\ny_train = y_train.apply(lambda x: classes.index(x))\ny_valid = y_valid.apply(lambda x: classes.index(x))\n\nX_train = pre(X_train.tolist(), return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)\nX_valid = pre(X_valid.tolist(), return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)\n#print(pre_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:08:26.092409Z","iopub.execute_input":"2022-07-03T02:08:26.092708Z","iopub.status.idle":"2022-07-03T02:08:26.152534Z","shell.execute_reply.started":"2022-07-03T02:08:26.092671Z","shell.execute_reply":"2022-07-03T02:08:26.151868Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\ninput_text = tf.keras.Input(shape=(MAX_LENGHT,), dtype=tf.int32, name=\"input\")\n#preprocessing = keras.layers.Lambda(lambda_layer, name=\"lambda_layer\")(text.tolist())\nbert_output = bert(input_text)\n\nnet = tf.keras.layers.Dropout(0.5, name='DropOut1')(bert_output['pooler_output'])\nnet = tf.keras.layers.Dense(units=768, activation='tanh', name='classifier')(net)\nnet = tf.keras.layers.Dropout(0.5, name='DropOut2')(net)\nnet = tf.keras.layers.Dense(units=len(classes), activation='softmax', name='output')(net)\n\nmodel = tf.keras.Model(input_text, net)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:08:26.881891Z","iopub.execute_input":"2022-07-03T02:08:26.882150Z","iopub.status.idle":"2022-07-03T02:08:33.745637Z","shell.execute_reply.started":"2022-07-03T02:08:26.882120Z","shell.execute_reply":"2022-07-03T02:08:33.744875Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"loss = tf.keras.losses.SparseCategoricalCrossentropy()\nmetrics = tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n              loss=loss,\n              metrics=metrics\n            )","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:08:33.747491Z","iopub.execute_input":"2022-07-03T02:08:33.747735Z","iopub.status.idle":"2022-07-03T02:08:33.770155Z","shell.execute_reply.started":"2022-07-03T02:08:33.747702Z","shell.execute_reply":"2022-07-03T02:08:33.769542Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:08:33.772487Z","iopub.execute_input":"2022-07-03T02:08:33.772980Z","iopub.status.idle":"2022-07-03T02:08:33.794809Z","shell.execute_reply.started":"2022-07-03T02:08:33.772943Z","shell.execute_reply":"2022-07-03T02:08:33.794076Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n                    x = X_train['input_ids'],\n                    y = y_train,\n                    validation_data = (X_valid['input_ids'], y_valid),\n                    epochs=100,\n                   shuffle=True\n                   )","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T02:08:33.796567Z","iopub.execute_input":"2022-07-03T02:08:33.796799Z","iopub.status.idle":"2022-07-03T02:11:27.364122Z","shell.execute_reply.started":"2022-07-03T02:08:33.796763Z","shell.execute_reply":"2022-07-03T02:11:27.363256Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nprint(history.history.keys())\nloss_train = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(len(loss_train))\n\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig('fig-loss.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:11:27.367672Z","iopub.execute_input":"2022-07-03T02:11:27.367886Z","iopub.status.idle":"2022-07-03T02:11:27.658754Z","shell.execute_reply.started":"2022-07-03T02:11:27.367859Z","shell.execute_reply":"2022-07-03T02:11:27.658081Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nprint(history.history.keys())\nacc_train = history.history['acc']\nacc_val = history.history['val_acc']\nepochs = range(len(acc_train))\n\nplt.plot(epochs, acc_train, 'g', label='Training Accuracy')\nplt.plot(epochs, acc_val, 'b', label='validation Accuracy')\nplt.title('Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig('fig-Accuracy.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:11:27.660007Z","iopub.execute_input":"2022-07-03T02:11:27.660288Z","iopub.status.idle":"2022-07-03T02:11:27.919831Z","shell.execute_reply.started":"2022-07-03T02:11:27.660249Z","shell.execute_reply":"2022-07-03T02:11:27.918057Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#print(classes)\nexample = \"اقرا لي الايميلات.\"\nids = pre(example, return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)['input_ids']\npred = model.predict(ids)\nindex = tf.math.argmax(pred[0])\nprint(classes[index] + \" with percentage: \" + str(pred[0][index] * 100) + \"\\n\")\n\nscores = {}\nfor i in range(len(classes)):\n    scores[classes[i]] = pred[0][i] * 100\n\nscores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\nfor k,v in scores.items():\n    print(k + \" with percentage: \" + \"{:.2f}\".format(v))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:13:17.939602Z","iopub.execute_input":"2022-07-03T02:13:17.940225Z","iopub.status.idle":"2022-07-03T02:13:18.015594Z","shell.execute_reply.started":"2022-07-03T02:13:17.940184Z","shell.execute_reply":"2022-07-03T02:13:18.014878Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#model.save('./intent_model.h5', save_format='h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:14:28.519065Z","iopub.execute_input":"2022-07-03T02:14:28.519347Z","iopub.status.idle":"2022-07-03T02:14:32.002824Z","shell.execute_reply.started":"2022-07-03T02:14:28.519315Z","shell.execute_reply":"2022-07-03T02:14:32.001481Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#from IPython.display import FileLink\n#FileLink(r'./intent_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T01:34:40.997250Z","iopub.execute_input":"2022-07-03T01:34:41.004105Z","iopub.status.idle":"2022-07-03T01:34:41.018435Z","shell.execute_reply.started":"2022-07-03T01:34:41.004041Z","shell.execute_reply":"2022-07-03T01:34:41.017598Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#!curl --upload-file './intent_model.h5' https://transfer.sh/intent_model.h5","metadata":{"execution":{"iopub.status.busy":"2022-07-03T02:15:09.759116Z","iopub.execute_input":"2022-07-03T02:15:09.759819Z","iopub.status.idle":"2022-07-03T02:18:50.339501Z","shell.execute_reply.started":"2022-07-03T02:15:09.759780Z","shell.execute_reply":"2022-07-03T02:18:50.338654Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}